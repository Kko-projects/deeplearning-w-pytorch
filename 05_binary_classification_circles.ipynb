{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZv+PyQSkqmbV/PrEaGpZ8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff_XSrnDTY1k"
      },
      "outputs": [],
      "source": [
        "# Binary classification on circular data using a simple neural network\n",
        "\n",
        "# Setting GPU: Notebook settings -> T3 GPU (for faster training)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "\n",
        "# Generate synthetic circular data (two concentric circles)\n",
        "n_pts = 500\n",
        "X, y = datasets.make_circles(n_samples=n_pts, random_state=123, noise=0.1, factor=0.2)\n",
        "\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "x_data = torch.Tensor(X)\n",
        "y_data = torch.Tensor(y.reshape(500, 1))  # Reshape to column vector\n",
        "\n",
        "print(x_data.shape, y_data.shape)  # Check shape of input and label tensors\n",
        "\n",
        "\n",
        "# Plot the data points by class\n",
        "def scatter_plot():\n",
        "    plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red')\n",
        "    plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue')\n",
        "\n",
        "scatter_plot()  # Show the data distribution\n",
        "\n",
        "\n",
        "# Define a simple neural network model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, H1, output_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, H1)  # First hidden layer\n",
        "        self.linear2 = nn.Linear(H1, output_size)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.linear(x))  # Apply sigmoid to first layer\n",
        "        x = torch.sigmoid(self.linear2(x))  # Apply sigmoid to output layer\n",
        "        return x\n",
        "\n",
        "    def predict(self, x):\n",
        "        return 1 if self.forward(x) >= 0.5 else 0  # Binary prediction\n",
        "\n",
        "\n",
        "# Create model instance\n",
        "model = Model(2, 4, 1)\n",
        "print(list(model.parameters()))  # View model parameters\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)  # Adam optimizer\n",
        "\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def get_accuracy(y_pred, y_true):\n",
        "    predicted = y_pred >= 0.5  # Convert probabilities to 0 or 1\n",
        "    correct = predicted.eq(y_true.bool())  # Compare with true labels\n",
        "    acc = correct.sum().item() / len(y_true)  # Compute accuracy\n",
        "    return acc\n",
        "\n",
        "\n",
        "# Training loop\n",
        "epochs = 1000\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "    optimizer.zero_grad()  # Reset gradients from previous step\n",
        "    y_pred = model(x_data)  # Forward pass (model prediction)\n",
        "    loss = criterion(y_pred, y_data)  # Compute loss\n",
        "\n",
        "    acc = get_accuracy(y_pred, y_data)  # Compute accuracy\n",
        "    print(f\"epoch: {i}, loss: {loss.item():.4f}, accuracy: {acc:.4f}\")\n",
        "\n",
        "    losses.append(loss.item())  # Store loss\n",
        "    accuracies.append(acc)  # Store accuracy\n",
        "    loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update weights\n",
        "\n",
        "\n",
        "# Plot training loss over epochs\n",
        "plt.figure()\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Training Loss')\n",
        "\n",
        "\n",
        "# Plot training accuracy over epochs\n",
        "plt.figure()\n",
        "plt.plot(range(epochs), accuracies)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Training Accuracy')\n",
        "\n",
        "\n",
        "# Visualize decision boundary\n",
        "def plot_decision_boundary(X, y):\n",
        "    x_span = np.linspace(min(X[:, 0]), max(X[:, 0])) # X-axis range\n",
        "    y_span = np.linspace(min(X[:, 1]), max(X[:, 1])) # Y-axis range\n",
        "    xx, yy = np.meshgrid(x_span, y_span)\n",
        "    grid = torch.Tensor(np.c_[xx.ravel(), yy.ravel()]) # Flatten grid for prediction\n",
        "    pred_func = model(grid)\n",
        "    z = pred_func.view(xx.shape).detach().numpy() # Reshape to match grid for plotting\n",
        "    plt.contourf(xx, yy, z)\n",
        "\n",
        "\n",
        "# Plot decision boundary and data points\n",
        "plt.figure()\n",
        "plot_decision_boundary(x_data, y_data)\n",
        "scatter_plot() # Overlay original data points\n",
        "plt.title('Decision Boundary')\n",
        "plt.show()"
      ]
    }
  ]
}