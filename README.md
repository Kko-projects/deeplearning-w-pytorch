# Deep Learning with PyTorch ðŸ§ ðŸ”¥

This repository contains my PyTorch deep learning study notes, experiments, and model training examples using datasets like MNIST.

### ðŸ§  Core Concepts
- 01 ~ 04

### ðŸ”¢ Classification Models
- 05 ~ 08

## ðŸ“˜ Notebooks

| No. | Notebook | Description |
|-----|----------|-------------|
| 01  | `01_tensor_basics.ipynb` | Tensor creation and basic operations |
| 02  | `02_tensor_gpu_autograd.ipynb` | Using GPU and automatic differentiation |
| 03  | `03_nn_module_and_forward.ipynb` | Custom model definition using nn.Module |
| 04  | `04_loss_and_optimizer.ipynb` | Loss functions and optimizers |
| 05  | `05_binary_classification_circles.ipynb` | Nonlinear classification with synthetic data |
| 06  | `06_mnist_training_and_confusion.ipynb` | MNIST training and confusion matrix evaluation |
| 07  | `07_mnist_batchnorm_models.ipynb` | BatchNorm applied to fully connected and conv models |
| 08  | `08_cifar10_mlp_vs_vgg.ipynb`            | CIFAR-10 classification using MLP and VGG models          |



## ðŸ”§ Tech Stack

- Python (PyTorch, torchvision, torch.nn, torch.optim)
- Jupyter / Google Colab
- NumPy, Pandas, Matplotlib, Seaborn
