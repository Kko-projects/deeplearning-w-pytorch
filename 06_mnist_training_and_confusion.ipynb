{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQmeoMlH70wo/dCDmQ/7hN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjSL_Aa1T3q1"
      },
      "outputs": [],
      "source": [
        "# Training a simple neural network on MNIST with confusion matrix visualization\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as datasets\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torch.autograd import variable\n",
        "\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "# Confusion Matrix Plot Function\n",
        "def plot_confusion_matrix(cm, target_names=None, cmap=None, normalize=True, labels=True, title='Confusion matrix'):\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.figure(figsize=(10, 15))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if labels:\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            val = \"{:0.4f}\".format(cm[i, j]) if normalize else \"{:,}\".format(cm[i, j])\n",
        "            plt.text(j, i, val, horizontalalignment='center',\n",
        "                     color='white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "# Load MNIST dataset\n",
        "def MNIST_DATA(root='./data', train=True, transforms=None, download=True, batch_size=32, num_worker=1):\n",
        "    print(\"[+] Get the MNIST DATA\")\n",
        "    mnist_train = datasets.MNIST(root=root, train=True, transform=T.ToTensor(), download=download)\n",
        "    mnist_test = datasets.MNIST(root=root, train=False, transform=T.ToTensor(), download=True)\n",
        "\n",
        "    train_loader = data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_worker)\n",
        "    test_loader = data.DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_worker)\n",
        "\n",
        "    print(\"[+] MNIST DATA Loaded\")\n",
        "    return mnist_train, mnist_test, train_loader, test_loader\n",
        "\n",
        "mnist_train, mnist_test, train_loader, test_loader = MNIST_DATA(batch_size=32)\n",
        "\n",
        "# Define Trainer class\n",
        "class Trainer():\n",
        "    def __init__(self, trainloader, testloader, net, optimizer, criterion):\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.net = net\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def train(self, epoch=100):\n",
        "        self.net.train()\n",
        "        for e in range(epoch):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(self.trainloader, 0):\n",
        "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.net(inputs)\n",
        "                loss = self.criterion(output, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                if i % 500 == 0:\n",
        "                    print('[%d, %5d] loss: %.3f' % (e + 1, i + 1, running_loss / 500))\n",
        "                    running_loss = 0.0\n",
        "                    self.test()\n",
        "        print('Finished Training')\n",
        "\n",
        "    def test(self):\n",
        "        self.net.eval()\n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            output = self.net(inputs)\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            correct, len(self.testloader.dataset), 100. * correct / len(self.testloader.dataset)))\n",
        "\n",
        "    def get_conf(self):\n",
        "        self.net.eval()\n",
        "        conf_matrix = torch.zeros(10, 10)\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            output = self.net(inputs)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            for num in range(output.shape[0]):\n",
        "                conf_matrix[pred[num], labels[num]] += 1\n",
        "        return conf_matrix\n",
        "\n",
        "# Define MNIST Network (Sigmoid)\n",
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(28 * 28, 30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.fc0(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Train using Sigmoid network\n",
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.01)\n",
        "\n",
        "trainer = Trainer(trainloader=train_loader, testloader=test_loader, net=mnist_net, optimizer=optimizer, criterion=criterion)\n",
        "trainer.train(epoch=10)\n",
        "trainer.test()\n",
        "plot_confusion_matrix(trainer.get_conf().cpu().numpy())\n",
        "\n",
        "# Train using ReLU network\n",
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(28 * 28, 30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.fc0(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001)\n",
        "\n",
        "trainer = Trainer(trainloader=train_loader, testloader=test_loader, net=mnist_net, optimizer=optimizer, criterion=criterion)\n",
        "trainer.train(epoch=10)\n",
        "trainer.test()\n",
        "plot_confusion_matrix(trainer.get_conf().cpu().numpy())\n",
        "\n",
        "# Count trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(mnist_net)\n",
        "\n",
        "# Alternative counting loop\n",
        "num = 0\n",
        "for param in mnist_net.parameters():\n",
        "    if param.requires_grad:\n",
        "        num += param.numel()\n",
        "print(num)"
      ]
    }
  ]
}